{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEG4KhBVdj0V"
      },
      "source": [
        "# 1. Install libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzGrF-HH_G5q",
        "outputId": "d320e0f7-64d5-4ce4-94ea-1168bf0a21ab"
      },
      "outputs": [],
      "source": [
        "!pip install -q mediapipe torch_geometric Pillow_heif\n",
        "print(\"Libraries installed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8cKwYeK3_Iwz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "from sklearn.datasets import fetch_lfw_people\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "from PIL import Image, UnidentifiedImageError\n",
        "from pillow_heif import register_heif_opener\n",
        "register_heif_opener()\n",
        "\n",
        "import mediapipe as mp\n",
        "from mediapipe.tasks import python\n",
        "from mediapipe.tasks.python import vision\n",
        "\n",
        "from torchvision import models, transforms\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Sequential, Linear, BatchNorm1d, ReLU\n",
        "from torch.utils.data import Dataset as TorchDataset\n",
        "\n",
        "from torch_geometric.nn import GINConv, global_mean_pool\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.data import Batch\n",
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "import networkx as nx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2I7OziPAdopO"
      },
      "source": [
        "# 2. Data Loading\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ku-eWqXF_Kq1"
      },
      "outputs": [],
      "source": [
        "# setup MediaPipe\n",
        "!wget -q -O face_landmarker.task https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\n",
        "base_options = python.BaseOptions(model_asset_path='face_landmarker.task')\n",
        "options = vision.FaceLandmarkerOptions(\n",
        "    base_options=base_options,\n",
        "    output_face_blendshapes=False,\n",
        "    output_facial_transformation_matrixes=False,\n",
        "    num_faces=1)\n",
        "detector = vision.FaceLandmarker.create_from_options(options)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ImyWHNq_NjG"
      },
      "outputs": [],
      "source": [
        "# define edges\n",
        "connections = list(vision.FaceLandmarksConnections.FACE_LANDMARKS_TESSELATION)\n",
        "src = [c[0] if isinstance(c, tuple) else c.start for c in connections]\n",
        "dst = [c[1] if isinstance(c, tuple) else c.end for c in connections]\n",
        "edge_index = torch.tensor([src + dst, dst + src], dtype=torch.long)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNCBpuh0_OFq",
        "outputId": "a97d9601-ac72-46da-bad4-af838a1c9cdd"
      },
      "outputs": [],
      "source": [
        "# setup and load MobileNetV2\n",
        "fe_device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Feature extraction on {fe_device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1GUXWSI1_SdB"
      },
      "outputs": [],
      "source": [
        "full_model = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.IMAGENET1K_V1)\n",
        "\n",
        "cnn_backbone = torch.nn.Sequential(*list(full_model.features.children())[:14])\n",
        "cnn_backbone.to(fe_device)\n",
        "cnn_backbone.eval()\n",
        "\n",
        "cnn_transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xPHAcshA_T6n"
      },
      "outputs": [],
      "source": [
        "def image_to_lightweight_graph(image_u8, original_index):\n",
        "    mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=image_u8)\n",
        "    detection_result = detector.detect(mp_image)\n",
        "    if not detection_result.face_landmarks: return None\n",
        "    landmarks = detection_result.face_landmarks[0]\n",
        "\n",
        "    # geometry features\n",
        "    geo_features = torch.tensor([[lm.x, lm.y, lm.z] for lm in landmarks],\n",
        "                                dtype=torch.float32).to(fe_device)\n",
        "\n",
        "    # CNN features\n",
        "    img_tensor = cnn_transform(image_u8).unsqueeze(0).to(fe_device)\n",
        "    with torch.no_grad():\n",
        "        feature_map = cnn_backbone(img_tensor)\n",
        "\n",
        "    # sampling\n",
        "    landmarks_xy = np.array([[lm.x, lm.y] for lm in landmarks], dtype=np.float32)\n",
        "    grid = torch.tensor(landmarks_xy * 2.0 - 1.0, device=fe_device).unsqueeze(0).unsqueeze(0)\n",
        "\n",
        "    sampled_feats = F.grid_sample(feature_map, grid, align_corners=False)\n",
        "    cnn_node_features = sampled_feats.squeeze(0).squeeze(1).permute(1, 0)\n",
        "\n",
        "    # concatenate\n",
        "    final_node_features = torch.cat([geo_features, cnn_node_features], dim=1)\n",
        "    idx_tensor = torch.tensor([original_index], dtype=torch.long)\n",
        "\n",
        "    data = Data(x=final_node_features.cpu().to(torch.float16),\n",
        "                edge_index=edge_index,\n",
        "                img_idx=idx_tensor)\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118,
          "referenced_widgets": [
            "62b44612292448e1ad19bcfea29a55a1",
            "be355fd0732b454893d4533d2d046f96",
            "442125977371485281329ebf79d45fe9",
            "d21f4763e34342c787a28d67d0d8b6b7",
            "cae34ff4705f49708b3075e03ab14d73",
            "c7a9b0da6ffb4d70a70fbae9740f6fd9",
            "7cfbab6823264fee960ac871ba8dfcf1",
            "120e8b97d9b444b2a0be6190a8de0a35",
            "af64e7aa5b99422dbcd56d0ee5450016",
            "6d1111071763450f9ec32d3804beb06b",
            "180e9903ddd04de4aa9f1213bd52ffc7"
          ]
        },
        "id": "MuuZJR3A_XX4",
        "outputId": "8b9d2b69-c81b-48eb-b371-71c33a7a2bd2"
      },
      "outputs": [],
      "source": [
        "# LFW\n",
        "print(\"Downloading LFW...\")\n",
        "lfw_people = fetch_lfw_people(min_faces_per_person=3, resize=1.0, color=True)\n",
        "images = lfw_people.images\n",
        "labels = lfw_people.target\n",
        "\n",
        "graph_dataset = []\n",
        "valid_labels = []\n",
        "\n",
        "print(\"Generating lightweight graphs...\")\n",
        "for i, (img, label) in tqdm(enumerate(zip(images, labels)), total=len(images)):\n",
        "    img_u8 = (img * 255).astype(np.uint8)\n",
        "    graph = image_to_lightweight_graph(img_u8, i)\n",
        "    if graph is not None:\n",
        "        graph.y = torch.tensor([label], dtype=torch.long)\n",
        "        graph_dataset.append(graph)\n",
        "        valid_labels.append(label)\n",
        "\n",
        "INPUT_DIM = graph_dataset[0].x.shape[1]\n",
        "print(f\"Final Node Feature Dimension: {INPUT_DIM}\")\n",
        "print(\"RAM usage should now be significantly lower.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDuWdoNGc9UP"
      },
      "source": [
        "# 3. Model and Evaluation Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AKBdDNs9BFHY"
      },
      "outputs": [],
      "source": [
        "# @title 3a. Define GAT Model\n",
        "from torch_geometric.nn import GATv2Conv, global_mean_pool\n",
        "\n",
        "class GATFaceGNN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels=128, out_channels=128, heads=4):\n",
        "        super(GATFaceGNN, self).__init__()\n",
        "\n",
        "        self.conv1 = GATv2Conv(in_channels, hidden_channels, heads=heads, concat=True)\n",
        "        self.conv2 = GATv2Conv(hidden_channels * heads, hidden_channels, heads=heads, concat=True)\n",
        "        self.conv3 = GATv2Conv(hidden_channels * heads, out_channels, heads=1, concat=False)\n",
        "\n",
        "        # Final projection to embedding space\n",
        "        self.lin = torch.nn.Linear(out_channels, out_channels)\n",
        "\n",
        "    def forward_one(self, data):\n",
        "        x, edge_index, batch = data.x.float(), data.edge_index, data.batch\n",
        "\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.elu(x)\n",
        "        x = F.dropout(x, p=0.4, training=self.training)\n",
        "\n",
        "        x_in2 = x\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = F.elu(x)\n",
        "        x = F.dropout(x, p=0.4, training=self.training)\n",
        "        # residual\n",
        "        x = x + x_in2\n",
        "\n",
        "        x = self.conv3(x, edge_index)\n",
        "\n",
        "        x = global_mean_pool(x, batch)\n",
        "\n",
        "        x = self.lin(x)\n",
        "\n",
        "        # L2 normalization\n",
        "        x = F.normalize(x, p=2, dim=1)\n",
        "        return x\n",
        "\n",
        "    def forward(self, data1, data2):\n",
        "        return self.forward_one(data1), self.forward_one(data2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NzqrnKSG-fzj"
      },
      "outputs": [],
      "source": [
        "# @title 3b. Train and Evaluation functions\n",
        "def evaluate_accuracy(loader, model, threshold=0.5):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_g1, batch_g2, targets in loader:\n",
        "            batch_g1 = batch_g1.to(device)\n",
        "            batch_g2 = batch_g2.to(device)\n",
        "            targets = targets.to(device)\n",
        "\n",
        "            emb1 = model.forward_one(batch_g1)\n",
        "            emb2 = model.forward_one(batch_g2)\n",
        "\n",
        "            dists = F.pairwise_distance(emb1, emb2)\n",
        "\n",
        "            predictions = (dists > threshold).float()\n",
        "\n",
        "            correct += (predictions == targets).sum().item()\n",
        "            total += targets.size(0)\n",
        "    return correct / total\n",
        "\n",
        "def train(model, criterion, optimizer, train_loader, val_loader, save_path, num_epochs: int = 100, restart_train: bool = False):\n",
        "  print(\"Starting training...\")\n",
        "\n",
        "  if restart_train:\n",
        "    model.load_state_dict(torch.load(save_path))\n",
        "    print(f\"Loaded model from {save_path} to continue training.\")\n",
        "\n",
        "  best_val_acc = 0.0\n",
        "  train_losses = []\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "      model.train()\n",
        "      running_loss = 0.0\n",
        "      for batch_a, batch_p, batch_n in train_loader:\n",
        "          batch_a, batch_p, batch_n = batch_a.to(device), batch_p.to(device), batch_n.to(device)\n",
        "\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          emb_a = model.forward_one(batch_a)\n",
        "          emb_p = model.forward_one(batch_p)\n",
        "          emb_n = model.forward_one(batch_n)\n",
        "\n",
        "          loss = criterion(emb_a, emb_p, emb_n)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          running_loss += loss.item()\n",
        "\n",
        "      avg_train_loss = running_loss / len(train_loader)\n",
        "      train_losses.append(avg_train_loss)\n",
        "\n",
        "      # val\n",
        "      val_acc = evaluate_accuracy(val_loader, model, threshold=0.5)\n",
        "      print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {avg_train_loss:.4f} | Val Acc: {val_acc*100:.2f}%\")\n",
        "\n",
        "      if val_acc > best_val_acc:\n",
        "          best_val_acc = val_acc\n",
        "          torch.save(model.state_dict(), save_path)\n",
        "          print(f\" >>> New Best Model Saved: Acc {best_val_acc*100:.2f}%\")\n",
        "\n",
        "  print(\"Training Complete\")\n",
        "  return model, train_losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "phJQ7Xjd-1ns"
      },
      "outputs": [],
      "source": [
        "# @title 3c. Evaluation on test set\n",
        "def evaluate_on_test_set(model, save_path, test_loader, val_loader):\n",
        "  model.load_state_dict(torch.load(save_path, map_location=torch.device('cpu')))\n",
        "\n",
        "  test_acc = evaluate_accuracy(test_loader, model, threshold=0.5)\n",
        "  print(f\"Final Test Accuracy: {test_acc*100:.2f}%\")\n",
        "\n",
        "  thresholds = np.arange(0.1, 1.5, 0.1)\n",
        "  best_thresh_acc = 0\n",
        "  best_thresh = 0\n",
        "\n",
        "  for t in thresholds:\n",
        "      acc = evaluate_accuracy(val_loader, model, threshold=t)\n",
        "      if acc > best_thresh_acc:\n",
        "          best_thresh_acc = acc\n",
        "          best_thresh = t\n",
        "\n",
        "  print(f\"Optimized Threshold on Val: {best_thresh}\")\n",
        "  final_acc = evaluate_accuracy(test_loader, model, threshold=best_thresh)\n",
        "  print(f\"Test Accuracy with Optimized Threshold: {final_acc*100:.2f}%\")\n",
        "\n",
        "  return best_thresh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5b4SdiXX_E4s"
      },
      "outputs": [],
      "source": [
        "# @title 3d. Metrics\n",
        "def metrics_and_curves(model, loader, path, thresh=0.5):\n",
        "  if os.path.exists(path):\n",
        "      model.load_state_dict(torch.load(path))\n",
        "      print(\"Loaded best model checkpoint.\")\n",
        "  else:\n",
        "      print(\"Warning: Checkpoint not found, using current model weights.\")\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  all_distances = []\n",
        "  all_labels = []\n",
        "\n",
        "  print(\"Running inference on Test Set...\")\n",
        "  with torch.no_grad():\n",
        "      for batch_g1, batch_g2, targets in loader:\n",
        "          batch_g1 = batch_g1.to(device)\n",
        "          batch_g2 = batch_g2.to(device)\n",
        "\n",
        "          emb1 = model.forward_one(batch_g1)\n",
        "          emb2 = model.forward_one(batch_g2)\n",
        "\n",
        "          dists = F.pairwise_distance(emb1, emb2)\n",
        "\n",
        "          all_distances.extend(dists.cpu().numpy())\n",
        "          all_labels.extend(targets.cpu().numpy())\n",
        "\n",
        "  all_distances = np.array(all_distances)\n",
        "  all_labels = np.array(all_labels)\n",
        "\n",
        "  final_threshold = thresh\n",
        "\n",
        "  pos_indices = (all_labels == 0)\n",
        "  neg_indices = (all_labels == 1)\n",
        "\n",
        "  pos_dists = all_distances[pos_indices]\n",
        "  neg_dists = all_distances[neg_indices]\n",
        "\n",
        "  print(f\"\\nStats:\")\n",
        "  print(f\"Mean Distance (Same Person): {np.mean(pos_dists):.4f} +/- {np.std(pos_dists):.4f}\")\n",
        "  print(f\"Mean Distance (Diff Person): {np.mean(neg_dists):.4f} +/- {np.std(neg_dists):.4f}\")\n",
        "  print(f\"Visualization Threshold: {final_threshold:.4f}\")\n",
        "\n",
        "  # plot histogram\n",
        "  plt.figure(figsize=(10, 6))\n",
        "\n",
        "  # histogram for \"Same Person\"\n",
        "  plt.hist(pos_dists, bins=30, alpha=0.6, color='green',\n",
        "          label=f'Same Person (Mean: {np.mean(pos_dists):.2f})', density=True)\n",
        "\n",
        "  # histogram for \"Different Person\"\n",
        "  plt.hist(neg_dists, bins=30, alpha=0.6, color='red',\n",
        "          label=f'Diff Person (Mean: {np.mean(neg_dists):.2f})', density=True)\n",
        "\n",
        "  plt.axvline(x=final_threshold, color='black', linestyle='--', linewidth=2,\n",
        "              label=f'Threshold ({final_threshold:.2f})')\n",
        "\n",
        "  plt.title(\"Test Set: Embedding Distance Distribution\", fontsize=14)\n",
        "  plt.xlabel(\"Euclidean Distance\", fontsize=12)\n",
        "  plt.ylabel(\"Density\", fontsize=12)\n",
        "  plt.legend(loc='upper right')\n",
        "  plt.grid(True, alpha=0.3)\n",
        "  plt.show()\n",
        "\n",
        "  # roc curve\n",
        "  y_true = (all_labels == 0).astype(int)\n",
        "  y_scores = -all_distances\n",
        "\n",
        "  fpr, tpr, thresholds_roc = roc_curve(y_true, y_scores)\n",
        "  roc_auc = auc(fpr, tpr)\n",
        "\n",
        "  thresholds = np.linspace(0, 4.0, 200)\n",
        "  far_list = []\n",
        "  frr_list = []\n",
        "\n",
        "  for t in thresholds:\n",
        "      preds_same = (all_distances < t)\n",
        "\n",
        "      fa = np.sum(preds_same & (all_labels == 1))\n",
        "      num_diff = np.sum(all_labels == 1)\n",
        "      far = fa / num_diff if num_diff > 0 else 0\n",
        "\n",
        "      fr = np.sum((~preds_same) & (all_labels == 0))\n",
        "      num_same = np.sum(all_labels == 0)\n",
        "      frr = fr / num_same if num_same > 0 else 0\n",
        "\n",
        "      far_list.append(far)\n",
        "      frr_list.append(frr)\n",
        "\n",
        "  far_list = np.array(far_list)\n",
        "  frr_list = np.array(frr_list)\n",
        "\n",
        "  # EER\n",
        "  idx_eer = np.nanargmin(np.abs(far_list - frr_list))\n",
        "  eer_val = (far_list[idx_eer] + frr_list[idx_eer]) / 2\n",
        "  eer_thresh = thresholds[idx_eer]\n",
        "\n",
        "  print(f\"--- Verification Results ---\")\n",
        "  print(f\"AUC: {roc_auc:.4f}\")\n",
        "  print(f\"EER: {eer_val*100:.2f}% at Threshold {eer_thresh:.4f}\")\n",
        "\n",
        "  fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "  # ROC curve\n",
        "  axes[0].plot(fpr, tpr, color='blue', lw=2, label=f'AUC = {roc_auc:.2f}')\n",
        "  axes[0].plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
        "  axes[0].set_xlabel('False Positive Rate (FAR)')\n",
        "  axes[0].set_ylabel('True Positive Rate (TAR)')\n",
        "  axes[0].set_title('ROC Curve')\n",
        "  axes[0].legend(loc=\"lower right\")\n",
        "  axes[0].grid(alpha=0.3)\n",
        "\n",
        "  # FAR vs FRR Curve\n",
        "  axes[1].plot(thresholds, far_list, label='FAR (False Accept)', color='red')\n",
        "  axes[1].plot(thresholds, frr_list, label='FRR (False Reject)', color='blue')\n",
        "  axes[1].axvline(eer_thresh, color='black', linestyle='--', label=f'EER Thresh ({eer_thresh:.2f})')\n",
        "  axes[1].scatter(eer_thresh, eer_val, color='black', zorder=5)\n",
        "  axes[1].set_xlabel('Distance Threshold')\n",
        "  axes[1].set_ylabel('Error Rate')\n",
        "  axes[1].set_title(f'FAR vs FRR (EER = {eer_val*100:.1f}%)')\n",
        "  axes[1].legend()\n",
        "  axes[1].grid(alpha=0.3)\n",
        "\n",
        "  # DET curve\n",
        "  axes[2].plot(far_list, frr_list, color='purple', lw=2)\n",
        "  axes[2].plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
        "  axes[2].scatter(eer_val, eer_val, color='black', label='EER')\n",
        "  axes[2].set_xlabel('False Accept Rate (FAR)')\n",
        "  axes[2].set_ylabel('False Reject Rate (FRR)')\n",
        "  axes[2].set_title('DET Curve')\n",
        "  axes[2].legend()\n",
        "  axes[2].grid(alpha=0.3)\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3zHBMJJSGu9K"
      },
      "outputs": [],
      "source": [
        "# @title 3e. CMC\n",
        "def evaluate_cmc(model, graphs, labels_list):\n",
        "    model.eval()\n",
        "\n",
        "    embeddings = []\n",
        "    labels = []\n",
        "\n",
        "    from torch_geometric.data import Batch\n",
        "    print(\"Extracting embeddings for CMC...\")\n",
        "    with torch.no_grad():\n",
        "        for i, graph in enumerate(graphs):\n",
        "            graph = graph.to(device)\n",
        "            batch = Batch.from_data_list([graph])\n",
        "            emb = model.forward_one(batch)\n",
        "            embeddings.append(emb.cpu())\n",
        "            labels.append(labels_list[i])\n",
        "\n",
        "    embeddings = torch.cat(embeddings)\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    unique_ids = np.unique(labels)\n",
        "    gallery_indices = []\n",
        "    probe_indices = []\n",
        "\n",
        "    for uid in unique_ids:\n",
        "        idxs = np.where(labels == uid)[0]\n",
        "        gallery_indices.append(idxs[0])\n",
        "        probe_indices.extend(idxs[1:])\n",
        "\n",
        "    if len(probe_indices) == 0:\n",
        "        print(\"Error: Not enough images per person to create Probes.\")\n",
        "        return\n",
        "\n",
        "    gallery_embs = embeddings[gallery_indices]\n",
        "    gallery_lbls = labels[gallery_indices]\n",
        "\n",
        "    probe_embs = embeddings[probe_indices]\n",
        "    probe_lbls = labels[probe_indices]\n",
        "\n",
        "    print(f\"Gallery Size: {len(gallery_embs)} | Probe Size: {len(probe_embs)}\")\n",
        "\n",
        "    # calculate CMC\n",
        "    dists = torch.cdist(probe_embs, gallery_embs, p=2)\n",
        "\n",
        "    ranks = np.zeros(len(gallery_lbls))\n",
        "\n",
        "    for i in range(len(probe_embs)):\n",
        "        true_label = probe_lbls[i]\n",
        "        p_dists = dists[i]\n",
        "        sorted_indices = torch.argsort(p_dists).numpy()\n",
        "        sorted_labels = gallery_lbls[sorted_indices]\n",
        "        match_positions = np.where(sorted_labels == true_label)[0]\n",
        "\n",
        "        if len(match_positions) > 0:\n",
        "            rank = match_positions[0]\n",
        "            ranks[rank:] += 1\n",
        "\n",
        "    cmc_curve = ranks / len(probe_embs)\n",
        "\n",
        "    print(f\"Rank-1 Accuracy: {cmc_curve[0]*100:.2f}%\")\n",
        "    print(f\"Rank-5 Accuracy: {cmc_curve[min(4, len(cmc_curve)-1)]*100:.2f}%\")\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(range(1, len(cmc_curve)+1), cmc_curve, marker='o', linestyle='-', color='green')\n",
        "    plt.xlabel('Rank')\n",
        "    plt.ylabel('Identification Rate (Accuracy)')\n",
        "    plt.title('CMC Curve (Cumulative Match Characteristic)')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.ylim([0, 1.05])\n",
        "    max_rank_plot = min(100, len(gallery_embs))\n",
        "    plt.xlim([1, max_rank_plot])\n",
        "    # plt.xticks(range(1, max_rank_plot+20))\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hU-vq0Y_dAsG"
      },
      "source": [
        "# 4. Dataloaders definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "srTX_qcFdD-6"
      },
      "outputs": [],
      "source": [
        "# @title 4a. Training Triplet Dataset\n",
        "class TripletGraphDataset(TorchDataset):\n",
        "    def __init__(self, graphs, labels):\n",
        "        self.graphs = graphs\n",
        "        self.labels = labels\n",
        "\n",
        "        self.label_to_indices = {}\n",
        "        for idx, label in enumerate(labels):\n",
        "            if label not in self.label_to_indices:\n",
        "                self.label_to_indices[label] = []\n",
        "            self.label_to_indices[label].append(idx)\n",
        "\n",
        "        self.valid_labels = [lbl for lbl, idxs in self.label_to_indices.items() if len(idxs) > 1]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # select anchor\n",
        "        anchor_label = random.choice(self.valid_labels)\n",
        "        positive_indices = self.label_to_indices[anchor_label]\n",
        "        idx_a, idx_p = random.sample(positive_indices, 2)\n",
        "        anchor_graph = self.graphs[idx_a]\n",
        "\n",
        "        # select positive\n",
        "        positive_graph = self.graphs[idx_p]\n",
        "\n",
        "        # select negative\n",
        "        negative_label = random.choice(self.valid_labels)\n",
        "        while negative_label == anchor_label:\n",
        "            negative_label = random.choice(self.valid_labels)\n",
        "        idx_n = random.choice(self.label_to_indices[negative_label])\n",
        "        negative_graph = self.graphs[idx_n]\n",
        "\n",
        "        return anchor_graph, positive_graph, negative_graph\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.graphs)\n",
        "\n",
        "class TripletCollater:\n",
        "    def __call__(self, batch):\n",
        "        anchors = [b[0] for b in batch]\n",
        "        positives = [b[1] for b in batch]\n",
        "        negatives = [b[2] for b in batch]\n",
        "\n",
        "        return Batch.from_data_list(anchors), Batch.from_data_list(positives), Batch.from_data_list(negatives)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w1hnlHlmLV84"
      },
      "outputs": [],
      "source": [
        "# @title 4. Testing Pair Dataset\n",
        "class GraphPairDataset(TorchDataset):\n",
        "    def __init__(self, graphs, labels):\n",
        "        self.graphs = graphs\n",
        "        self.labels = labels\n",
        "        self.label_to_indices = {label: np.where(np.array(labels) == label)[0]\n",
        "                                 for label in set(labels)}\n",
        "        self.unique_labels = list(self.label_to_indices.keys())\n",
        "        self.valid_indices = [i for i,label in enumerate(labels)\n",
        "                              if len(self.label_to_indices[label]) > 1]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        idx1 = self.valid_indices[index]\n",
        "        graph1 = self.graphs[idx1]\n",
        "        label1 = self.labels[idx1]\n",
        "\n",
        "        should_match = random.random() > 0.5\n",
        "\n",
        "        if should_match:\n",
        "            possible_indices = self.label_to_indices[label1]\n",
        "            idx2 = random.choice([i for i in possible_indices if i != idx1])\n",
        "            target = 0.0\n",
        "        else:\n",
        "            label2 = random.choice([l for l in self.unique_labels if l != label1])\n",
        "            idx2 = random.choice(self.label_to_indices[label2])\n",
        "            target = 1.0\n",
        "\n",
        "        graph2 = self.graphs[idx2]\n",
        "        return graph1, graph2, torch.tensor(target, dtype=torch.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.valid_indices)\n",
        "\n",
        "class PairCollater:\n",
        "    def __call__(self, batch):\n",
        "        g1 = Batch.from_data_list([b[0] for b in batch])\n",
        "        g2 = Batch.from_data_list([b[1] for b in batch])\n",
        "        t = torch.stack([b[2] for b in batch])\n",
        "        return g1, g2, t"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VL93djXHDDI3"
      },
      "source": [
        "# 5. Closed-Set Scenario"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "4BpLHgwTsh9y",
        "outputId": "902c1125-f3f5-48c2-c7f9-f0bb4caa060e"
      },
      "outputs": [],
      "source": [
        "# @title 5a. Image-based Split & Dataloaders (Closed-set)\n",
        "for graph in graph_dataset:\n",
        "  graph.to('cpu')\n",
        "\n",
        "indices = np.arange(len(graph_dataset))\n",
        "\n",
        "# split indices randomly\n",
        "close_train_idx, close_temp_idx = train_test_split(indices, test_size=0.2, random_state=42)\n",
        "close_val_idx, close_test_idx = train_test_split(close_temp_idx, test_size=0.5, random_state=42)\n",
        "\n",
        "def get_subset(idx_list):\n",
        "    graphs = [graph_dataset[i] for i in idx_list]\n",
        "    labels = [valid_labels[i] for i in idx_list]\n",
        "    return graphs, labels\n",
        "\n",
        "close_train_graphs, close_train_labels = get_subset(close_train_idx)\n",
        "close_val_graphs, close_val_labels = get_subset(close_val_idx)\n",
        "close_test_graphs, close_test_labels = get_subset(close_test_idx)\n",
        "\n",
        "print(f\"Closed Set Split Complete:\")\n",
        "print(f\"Total Unique IDs in Full Set: {len(set(valid_labels))}\")\n",
        "print(f\"Training samples: {len(close_train_graphs)} (Unique IDs: {len(set(close_train_labels))})\")\n",
        "print(f\"Validation samples: {len(close_val_graphs)} (Unique IDs: {len(set(close_val_labels))})\")\n",
        "print(f\"Testing samples: {len(close_test_graphs)} (Unique IDs: {len(set(close_test_labels))})\")\n",
        "\n",
        "# initialize dataloaders\n",
        "close_train_ds = TripletGraphDataset(close_train_graphs, close_train_labels)\n",
        "close_train_loader = torch.utils.data.DataLoader(\n",
        "    close_train_ds, batch_size=32, shuffle=True, collate_fn=TripletCollater()\n",
        ")\n",
        "\n",
        "close_val_ds = GraphPairDataset(close_val_graphs, close_val_labels)\n",
        "close_val_loader = torch.utils.data.DataLoader(\n",
        "    close_val_ds, batch_size=32, shuffle=False, collate_fn=PairCollater()\n",
        ")\n",
        "\n",
        "close_test_ds = GraphPairDataset(close_test_graphs, close_test_labels)\n",
        "close_test_loader = torch.utils.data.DataLoader(\n",
        "    close_test_ds, batch_size=32, shuffle=False, collate_fn=PairCollater()\n",
        ")\n",
        "\n",
        "print(\"Closed-set Dataloaders ready.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tduv5tAGD3Fg",
        "outputId": "24620f6c-cf2d-423d-8761-b319b4e0ab90"
      },
      "outputs": [],
      "source": [
        "# @title 5b. Init Model\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Training on {device}\")\n",
        "\n",
        "close_model = GATFaceGNN(in_channels=INPUT_DIM).to(device)\n",
        "criterion = torch.nn.TripletMarginLoss(margin=0.5, p=2)\n",
        "\n",
        "optimizer = torch.optim.Adam(close_model.parameters(), lr=0.001, weight_decay=5e-4)\n",
        "\n",
        "num_epochs = 100\n",
        "\n",
        "base_save_path = \"close_gnn.pth\"\n",
        "if os.path.exists('/content/drive/MyDrive'):\n",
        "    drive_dir = '/content/drive/MyDrive/biosys'\n",
        "    os.makedirs(drive_dir, exist_ok=True)\n",
        "    close_save_path = os.path.join(drive_dir, base_save_path)\n",
        "    print(f\"Saving model to Google Drive: {close_save_path}\")\n",
        "else:\n",
        "    close_save_path = base_save_path\n",
        "    print(f\"Saving model locally: {close_save_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 975
        },
        "id": "TDNuEKBJE1pS",
        "outputId": "9b71cca7-ea98-4025-efe9-c7bba3be0bc6"
      },
      "outputs": [],
      "source": [
        "# @title 5c. Train and Print Losses\n",
        "close_model, close_train_losses = train(close_model,\n",
        "                                        criterion,\n",
        "                                        optimizer,\n",
        "                                        close_train_loader,\n",
        "                                        close_val_loader,\n",
        "                                        close_save_path,\n",
        "                                        25,\n",
        "                                        False)\n",
        "\n",
        "# Loss plot\n",
        "plt.plot(close_train_losses)\n",
        "plt.title(\"Triplet Loss Curve\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUqDiCWIFMr4",
        "outputId": "b2007baf-49b5-427e-e5e8-a0e98891a8c2"
      },
      "outputs": [],
      "source": [
        "# @title 5d. Test Set Evaluation\n",
        "best_thresh = evaluate_on_test_set(close_model,\n",
        "                                   close_save_path,\n",
        "                                   close_test_loader,\n",
        "                                   close_val_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pF2yL50jFjIn",
        "outputId": "760121ad-db8c-4568-c599-ac71554139c6"
      },
      "outputs": [],
      "source": [
        "# @title 5e. Metrics and Curves and CMC\n",
        "metrics_and_curves(close_model,\n",
        "                   close_test_loader,\n",
        "                   close_save_path,\n",
        "                   float(best_thresh))\n",
        "\n",
        "evaluate_cmc(close_model, close_test_graphs, close_test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krtwldemHbn6"
      },
      "source": [
        "# 6. Open-Set Scenario"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "uB-POqG6XpH_",
        "outputId": "33b0dd3e-39df-4b97-8652-c80cde9f9b06"
      },
      "outputs": [],
      "source": [
        "# @title 6a. Identity-based Split & Dataloaders (Open-set)\n",
        "for graph in graph_dataset:\n",
        "  graph.to('cpu')\n",
        "\n",
        "unique_ids = list(set(valid_labels))\n",
        "print(f\"Total unique identities: {len(unique_ids)}\")\n",
        "\n",
        "# split by identities\n",
        "open_train_ids, open_temp_ids = train_test_split(unique_ids, test_size=0.2, random_state=42)\n",
        "open_val_ids, open_test_ids = train_test_split(open_temp_ids, test_size=0.5, random_state=42)\n",
        "print(f\"Train IDs: {len(open_train_ids)} | Val IDs: {len(open_val_ids)} | Test IDs: {len(open_test_ids)}\")\n",
        "\n",
        "# filter graphs based on identities\n",
        "def filter_graphs(ids_list):\n",
        "    id_set = set(ids_list)\n",
        "    graphs = []\n",
        "    labels = []\n",
        "    for graph, label in zip(graph_dataset, valid_labels):\n",
        "        if label in id_set:\n",
        "            graphs.append(graph)\n",
        "            labels.append(label)\n",
        "    return graphs, labels\n",
        "\n",
        "open_train_graphs, open_train_labels = filter_graphs(open_train_ids)\n",
        "open_val_graphs, open_val_labels = filter_graphs(open_val_ids)\n",
        "open_test_graphs, open_test_labels = filter_graphs(open_test_ids)\n",
        "\n",
        "print(f\"Training graphs: {len(open_train_graphs)}\")\n",
        "print(f\"Validation graphs: {len(open_val_graphs)}\")\n",
        "print(f\"Testing graphs: {len(open_test_graphs)}\")\n",
        "\n",
        "open_train_ds = TripletGraphDataset(open_train_graphs, open_train_labels)\n",
        "open_train_loader = torch.utils.data.DataLoader(\n",
        "    open_train_ds,\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    collate_fn=TripletCollater()\n",
        "    )\n",
        "\n",
        "open_val_ds = GraphPairDataset(open_test_graphs, open_test_labels)\n",
        "open_val_loader = torch.utils.data.DataLoader(\n",
        "    open_val_ds,\n",
        "    batch_size=32,\n",
        "    shuffle=False,\n",
        "    collate_fn=PairCollater()\n",
        "    )\n",
        "\n",
        "open_test_ds = GraphPairDataset(open_test_graphs, open_test_labels)\n",
        "open_test_loader = torch.utils.data.DataLoader(\n",
        "    open_test_ds,\n",
        "    batch_size=32,\n",
        "    shuffle=False,\n",
        "    collate_fn=PairCollater()\n",
        "    )\n",
        "\n",
        "print(\"Dataloaders ready.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5bzVaTZIUqU",
        "outputId": "14659847-238e-4740-9fb5-99391c56e020"
      },
      "outputs": [],
      "source": [
        "# @title 6b. Init Model\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Training on {device}\")\n",
        "\n",
        "open_model = GATFaceGNN(in_channels=INPUT_DIM).to(device)\n",
        "criterion = torch.nn.TripletMarginLoss(margin=0.5, p=2)\n",
        "\n",
        "optimizer = torch.optim.Adam(open_model.parameters(), lr=0.001, weight_decay=5e-4)\n",
        "\n",
        "num_epochs = 100\n",
        "\n",
        "base_save_path = \"open_gnn.pth\"\n",
        "if os.path.exists('/content/drive/MyDrive'):\n",
        "    drive_dir = '/content/drive/MyDrive/biosys'\n",
        "    os.makedirs(drive_dir, exist_ok=True)\n",
        "    open_save_path = os.path.join(drive_dir, base_save_path)\n",
        "    print(f\"Saving model to Google Drive: {close_save_path}\")\n",
        "else:\n",
        "    open_save_path = base_save_path\n",
        "    print(f\"Saving model locally: {close_save_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A3Uyv3b9iOgX"
      },
      "outputs": [],
      "source": [
        "# @title 6c. Train and Print Losses\n",
        "open_model, open_train_losses = train(open_model,\n",
        "                                      criterion,\n",
        "                                      optimizer,\n",
        "                                      open_train_loader,\n",
        "                                      open_val_loader,\n",
        "                                      open_save_path,\n",
        "                                      50,\n",
        "                                      False)\n",
        "\n",
        "# Loss plot\n",
        "plt.plot(open_train_losses)\n",
        "plt.title(\"Triplet Loss Curve\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDhysRppI7Vt",
        "outputId": "9556c747-9169-4381-ad43-2f212fcec71a"
      },
      "outputs": [],
      "source": [
        "# @title 6d. Test Set Evaluation\n",
        "best_thresh = evaluate_on_test_set(open_model,\n",
        "                                   open_save_path,\n",
        "                                   open_test_loader,\n",
        "                                   open_val_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Qzd2iJ5NJKB1",
        "outputId": "518bfd1c-0cf9-43e8-b865-3b69280cb90c"
      },
      "outputs": [],
      "source": [
        "# @title 6e. Metrics and Curves and CMC\n",
        "metrics_and_curves(open_model,\n",
        "                   open_test_loader,\n",
        "                   open_save_path,\n",
        "                   float(best_thresh))\n",
        "\n",
        "evaluate_cmc(open_model,\n",
        "             open_test_graphs,\n",
        "             open_test_labels)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "MfL2Uu7vCxCF",
        "s1w1wwV7JaAc"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "120e8b97d9b444b2a0be6190a8de0a35": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "180e9903ddd04de4aa9f1213bd52ffc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "442125977371485281329ebf79d45fe9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_120e8b97d9b444b2a0be6190a8de0a35",
            "max": 7606,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_af64e7aa5b99422dbcd56d0ee5450016",
            "value": 7606
          }
        },
        "62b44612292448e1ad19bcfea29a55a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_be355fd0732b454893d4533d2d046f96",
              "IPY_MODEL_442125977371485281329ebf79d45fe9",
              "IPY_MODEL_d21f4763e34342c787a28d67d0d8b6b7"
            ],
            "layout": "IPY_MODEL_cae34ff4705f49708b3075e03ab14d73"
          }
        },
        "6d1111071763450f9ec32d3804beb06b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7cfbab6823264fee960ac871ba8dfcf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "af64e7aa5b99422dbcd56d0ee5450016": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "be355fd0732b454893d4533d2d046f96": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7a9b0da6ffb4d70a70fbae9740f6fd9",
            "placeholder": "",
            "style": "IPY_MODEL_7cfbab6823264fee960ac871ba8dfcf1",
            "value": "100%"
          }
        },
        "c7a9b0da6ffb4d70a70fbae9740f6fd9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cae34ff4705f49708b3075e03ab14d73": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d21f4763e34342c787a28d67d0d8b6b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d1111071763450f9ec32d3804beb06b",
            "placeholder": "",
            "style": "IPY_MODEL_180e9903ddd04de4aa9f1213bd52ffc7",
            "value": "7606/7606[03:32&lt;00:00,32.67it/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
